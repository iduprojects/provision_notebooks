{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47e889b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:95% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d774a625",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/python_venvs/common_venv/lib/python3.8/site-packages/geopandas/_compat.py:106: UserWarning: The Shapely GEOS version (3.8.0-CAPI-1.13.1 ) is incompatible with the GEOS version PyGEOS was compiled with (3.9.1-CAPI-1.14.2). Conversions between both will be slow.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import json\n",
    "import shapely\n",
    "import networkx as nx\n",
    "import osmnx as ox\n",
    "from multiprocesspandas import applyparallel\n",
    "from tqdm.notebook import trange, tqdm \n",
    "tqdm.pandas()\n",
    "import scipy\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from sqlalchemy import create_engine\n",
    "engine = create_engine(\"postgresql://postgres:postgres@10.32.1.101/city_db_final\")\n",
    "import osmnx as ox \n",
    "import networkx as nx\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2bf43de7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79c4a8b2a3dc43b29f05a79ba07fc3b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/169 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a603e0263a0943b7b129c96d04927ea3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/163 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1ad7ea81f914ad3a5324ef7db3a9471",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/76 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of manager items must equal union of block items\n",
      "# manager items: 6, # tot_items: 5 dog_playgrounds\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05c9285d0dfb43d785aa67b33bb90aeb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/77 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ca8af286e8946ddba02c751aebafa0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/76 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def eval_(loc):\n",
    "    try:\n",
    "        return eval(loc)\n",
    "    except:\n",
    "        return loc\n",
    "\n",
    "service_types_normatives = pd.read_sql('''SELECT l.*\n",
    "                                         FROM public.city_service_types l''', con = engine)\n",
    "#houses original\n",
    "houses_pt_1 = pd.read_csv('/media/sf_shared/itmo/data/other/new_provosion/data/houses_prepeared_normative.csv', sep = ';')\n",
    "houses_pt_1 = houses_pt_1.set_index(houses_pt_1['functional_object_id'])\n",
    "houses_pt_1 = gpd.GeoDataFrame(houses_pt_1, geometry = houses_pt_1['geometry'].apply(lambda x: shapely.wkt.loads(x)), crs = 3857)\n",
    "for column in tqdm(houses_pt_1.columns):\n",
    "    houses_pt_1[column] = houses_pt_1[column].apply(lambda x: eval_(x))\n",
    "houses_pt_1 = houses_pt_1.drop(columns = ['functional_object_id'])\n",
    "#houses provision processed  \n",
    "houses_pt_2 = pd.read_csv('/media/sf_shared/itmo/data/other/new_provosion/data/provision_results/normative/houses_prepeared_normative_origin_provision.csv', sep = ';')    \n",
    "houses_pt_2 = houses_pt_2.set_index(houses_pt_2['functional_object_id'])\n",
    "houses_pt_2 = gpd.GeoDataFrame(houses_pt_2, geometry = houses_pt_2['geometry'].apply(lambda x: shapely.wkt.loads(x)), crs = 3857)\n",
    "for column in tqdm(houses_pt_2.columns):\n",
    "    houses_pt_2[column] = houses_pt_2[column].apply(lambda x: eval_(x))\n",
    "houses_pt_2.drop(columns = 'Unnamed: 0', inplace = True)\n",
    "houses_pt_2 = houses_pt_2.drop(columns = ['functional_object_id'])\n",
    "#houses final processed\n",
    "mypath = '/media/sf_shared/itmo/data/other/new_provosion/data/provision_results/normative/original_provision/'\n",
    "houses_pt_3 = [f for f in listdir(mypath) if isfile(join(mypath, f)) if 'houses' in f]\n",
    "for f in houses_pt_3[:1]:\n",
    "    houses_pt_3_df = pd.read_csv(mypath + f, sep = \";\")\n",
    "for f in tqdm(houses_pt_3[1:]):\n",
    "    tmp = pd.read_csv(mypath + f, sep = \";\")\n",
    "    try:\n",
    "        tmp.drop(columns = ['geometry', 'provision_len'], inplace = True)\n",
    "    except:\n",
    "        tmp.drop(columns = ['geometry'], inplace = True)\n",
    "    houses_pt_3_df = houses_pt_3_df.merge(tmp, how = 'left', on = 'functional_object_id')\n",
    "houses_pt_3_df = houses_pt_3_df.set_index(houses_pt_3_df['functional_object_id'])\n",
    "houses_pt_3_df = houses_pt_3_df.drop(columns = ['functional_object_id'])\n",
    "houses_pt_3_df.rename(columns = {old:old+'_processed' for old in [x for x in houses_pt_3_df.columns if 'normative_value' in x]}, inplace = True)\n",
    "houses_pt_3_df.rename(columns = {old:old+'_processed' for old in [x for x in houses_pt_3_df.columns if '_provision_indices' in x]}, inplace = True)\n",
    "houses_pt_3_df = houses_pt_3_df.rename(columns = {old:old+'_processed' for old in [x for x in houses_pt_3_df.columns if 'normative_value' in x]})\n",
    "#build result df\n",
    "houses_result = houses_pt_1.merge(houses_pt_2.drop(columns = ['geometry']), left_index = True, right_index = True, suffixes=('_original','_provision'))\n",
    "houses_result = houses_result.merge(houses_pt_3_df.drop(columns = ['geometry']), left_index = True, right_index = True)\n",
    "service_names = [x.split('_normative_value')[0] for x in houses_result.columns if '_normative_value_processed' in x]\n",
    "houses_result = houses_result.reindex(sorted(houses_result.columns), axis=1)\n",
    "houses_result = houses_result[[y for y in houses_result.columns for x in service_names if x in y ]]\n",
    "for service_name in service_names: \n",
    "    try:\n",
    "        houses_result[service_name + '_normative_provision'] = \\\n",
    "             (houses_result[service_name + '_normative_value_original'] - \\\n",
    "             houses_result[service_name + '_normative_value_provision'])/ \\\n",
    "             houses_result[service_name + '_normative_value_original']\n",
    "    except Exception as e: \n",
    "        print(e,service_name)\n",
    "service_names = [x.split('_normative_provision')[0] for x in houses_result.columns if '_normative_provision' in x]\n",
    "houses_result = houses_result[[y for y in houses_result.columns for x in service_names if x in y ]]\n",
    "houses_additional_info = pd.read_sql('''SELECT ST_AsGeoJSON(t.geometry) as geometry_geojson, t.*\n",
    "                                        FROM provision.buildings_load t\n",
    "                                        WHERE city_id = 1''', con = engine)\n",
    "houses_additional_info = houses_additional_info[[x for x in houses_additional_info.columns if 'demand' not in x]]\n",
    "houses_additional_info = houses_additional_info.set_index(houses_additional_info['functional_object_id'])\n",
    "houses_additional_info.geometry = houses_additional_info['geometry_geojson']\n",
    "houses_additional_info.drop(columns = ['geometry_geojson'], inplace = True)\n",
    "houses_result = houses_result.merge(houses_additional_info, left_index = True, right_index = True)\n",
    "mypath = '/media/sf_shared/itmo/data/other/new_provosion/data/provision_results/normative/'\n",
    "provision_pt_1 = [f for f in listdir(mypath) if isfile(join(mypath, f)) if 'services' in f]\n",
    "provision_pt_1_df = pd.DataFrame() \n",
    "for f in tqdm(provision_pt_1):\n",
    "    provision_pt_1_df = provision_pt_1_df.append(pd.read_csv(mypath + f, sep = \";\"))\n",
    "provision_pt_1_df.set_index(provision_pt_1_df['functional_object_id'], inplace = True)\n",
    "provision_pt_1_df.drop(columns = ['functional_object_id', 'functional_object_id.1'],inplace = True)\n",
    "provision_pt_1_df.rename(columns = {'houses_provision':'houses_indices',\n",
    "                                    'houses_demand_sum':'houses_total_demand_original_normative',\n",
    "                                    'houses_demand': 'houses_demand_original_normative',\n",
    "                                    'free_capacity':'free_capacity_original_normative'}, inplace = True)\n",
    "mypath = '/media/sf_shared/itmo/data/other/new_provosion/data/provision_results/normative/original_provision/'\n",
    "provision_pt_2 = [f for f in listdir(mypath) if isfile(join(mypath, f)) if 'services' in f]\n",
    "provision_pt_2_df = pd.DataFrame() \n",
    "for f in tqdm(provision_pt_2):\n",
    "    provision_pt_2_df = provision_pt_2_df.append(pd.read_csv(mypath + f, sep = \";\"))\n",
    "provision_pt_2_df.set_index(provision_pt_2_df['functional_object_id'], inplace = True)\n",
    "provision_pt_2_df.drop(columns = ['functional_object_id', 'functional_object_id.1','functional_object_id.1.1'],inplace = True)\n",
    "provision_pt_2_df.rename(columns = {'houses_provision':'houses_indices',\n",
    "                                    'houses_demand_sum':'houses_total_demand_processed_normative',\n",
    "                                    'houses_demand': 'houses_demand_processed_normative',\n",
    "                                    'free_capacity':'free_capacity_processed_normative'}, inplace = True)\n",
    "services_result = provision_pt_1_df.merge(provision_pt_2_df[['houses_demand_processed_normative',\n",
    "                                           'houses_total_demand_processed_normative',\n",
    "                                           'free_capacity_processed_normative']], left_index = True, \n",
    "                                                                                  right_index = True)\n",
    "extra_services_info = pd.read_sql('''SELECT functional_object_id, service_name, address\n",
    "                                     FROM public.all_services\n",
    "                                     WHERE city_id = 1''', con = engine)\n",
    "extra_services_info = extra_services_info.set_index(extra_services_info['functional_object_id']).drop(columns = 'functional_object_id')\n",
    "services_result = services_result.merge(extra_services_info, left_index = True, right_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "594719c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "services_result.to_csv('/media/sf_shared/itmo/data/other/new_provosion/data/provision_results/services_result_normative.csv', sep = ';')\n",
    "houses_result.to_csv('/media/sf_shared/itmo/data/other/new_provosion/data/provision_results/houses_result_normative.csv', sep = ';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e91229f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74593ca7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "houses_prepeared_normative = pd.read_csv('/media/sf_shared/itmo/data/other/new_provosion/data/houses_prepeared_normative.csv', sep = ';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f8f935",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3209726",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "provision_results_services_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8610b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "houses = pd.read_csv('/media/sf_shared/itmo/data/other/new_provosion/data/houses_prepeared.csv', sep = ';')\n",
    "houses.set_index(houses['functional_object_id'], inplace = True)\n",
    "services = pd.read_csv('/media/sf_shared/itmo/data/other/new_provosion/data/services_prepeared.csv', sep = ';')\n",
    "services = services.drop(index = services[services['city_service_type_code'] == 'houses'].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e67a8939",
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_services_info = pd.read_sql('''SELECT functional_object_id, service_name, address\n",
    "                                     FROM public.all_services\n",
    "                                     WHERE city_id = 1''', con = engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4947e33c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "provision_results_services_df = pd.DataFrame() \n",
    "for f in provision_results_services:\n",
    "    provision_results_services_df = provision_results_services_df.append(pd.read_csv(mypath + f, sep = \";\"))\n",
    "provision_results_services_df.set_index(provision_results_services_df['functional_object_id'], inplace = True)\n",
    "provision_results_services_df.drop(columns = 'functional_object_id.1',inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195d816f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for f in provision_results_houses[:1]:\n",
    "    provision_results_houses_df = pd.read_csv(mypath + f, sep = \";\")\n",
    "for f in tqdm(provision_results_houses[1:]):\n",
    "    provision_results_houses_df_2 = pd.read_csv(mypath + f, sep = \";\")\n",
    "    try:\n",
    "        provision_results_houses_df_2.drop(columns = ['geometry', 'provision_len'], inplace = True)\n",
    "    except:\n",
    "        provision_results_houses_df_2.drop(columns = ['geometry'], inplace = True)\n",
    "    provision_results_houses_df = provision_results_houses_df.merge(provision_results_houses_df_2, how = 'left', on = 'functional_object_id')\n",
    "provision_results_houses_df.drop(columns = ['functional_object_id.1'],inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba43d654",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
